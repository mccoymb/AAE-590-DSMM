{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPebuzxGCRpdGIPYHvQ60IQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mccoymb/AAE-590-DSMM/blob/main/590DSMM_Lecture15_EX2_SVR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k44LcJgP-tSM"
      },
      "outputs": [],
      "source": [
        "# Data wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data visualisation\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "boston = load_california()\n",
        "data = pd.DataFrame(california.data, columns = california.feature_names)\n",
        "data['target'] = boston.target\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Im9Hy2TS-8Dv",
        "outputId": "1193c365-e3c7-443c-f435-fe6672bf9da6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_california' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-be215bd2a6c2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mboston\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_california\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalifornia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalifornia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboston\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_california' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values and data type\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "vWM21HwU--3L",
        "outputId": "a0a331eb-9735-4b28-a6bb-954bccac124f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'info'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-185ac1ff5d90>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Missing values and data type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'info'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics\n",
        "\n",
        "data.describe().transpose()"
      ],
      "metadata": {
        "id": "2czbsfrG-_ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Get predictor and target variables\n",
        "X = data.drop('target', axis = 1)\n",
        "Y = data['target']\n",
        "\n",
        "# X, Y shape\n",
        "print(\"X shape: \", X.shape)\n",
        "print(\"Y shape: \", Y.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "Rjp6CLm0_Ckn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Instantiate MinMaxScaler, StandardScaler and RobustScaler\n",
        "\n",
        "norm = MinMaxScaler()\n",
        "standard = StandardScaler()\n",
        "robust = RobustScaler()\n",
        "\n"
      ],
      "metadata": {
        "id": "dpP_WEtQ_Fu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# MinMaxScaler\n",
        "normalised_features = norm.fit_transform(X)\n",
        "normalised_df = pd.DataFrame(normalised_features, index = X.index, columns = X.columns)\n",
        "\n",
        "# StandardScaler\n",
        "standardised_features = standard.fit_transform(X)\n",
        "standardised_df = pd.DataFrame(standardised_features, index = X.index, columns = X.columns)\n",
        "\n",
        "# RobustScaler\n",
        "robust_features = robust.fit_transform(X)\n",
        "robust_df = pd.DataFrame(robust_features, index = X.index, columns = X.columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "WaZkzQsE_Hvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subplots\n",
        "fig, ax = plt.subplots(2, 2, figsize = (12, 9))\n",
        "\n",
        "# Original\n",
        "sns.boxplot(x = 'variable', y = 'value', data = pd.melt(data[['ZN', 'AGE', 'TAX', 'B']]), ax = ax[0, 0])\n",
        "ax[0, 0].set_title('Original')\n",
        "ax[0, 0].set_xlabel('')\n",
        "ax[0, 0].set_ylabel('')\n",
        "\n",
        "# MinMaxScaler\n",
        "sns.boxplot(x = 'variable', y = 'value', data = pd.melt(normalised_df[['ZN', 'AGE', 'TAX', 'B']]), ax = ax[0, 1])\n",
        "ax[0, 1].set_title('MinMaxScaler')\n",
        "ax[0, 1].set_xlabel('')\n",
        "ax[0, 1].set_ylabel('')\n",
        "\n",
        "# StandardScaler\n",
        "sns.boxplot(x = 'variable', y = 'value', data = pd.melt(standardised_df[['ZN', 'AGE', 'TAX', 'B']]), ax = ax[1, 0])\n",
        "ax[1, 0].set_title('StandardScaler')\n",
        "ax[1, 0].set_xlabel('')\n",
        "ax[1, 0].set_ylabel('')\n",
        "\n",
        "# RobustScaler\n",
        "sns.boxplot(x = 'variable', y = 'value', data = pd.melt(robust_df[['ZN', 'AGE', 'TAX', 'B']]), ax = ax[1, 1])\n",
        "ax[1, 1].set_title('RobustScaler')\n",
        "ax[1, 1].set_xlabel('')\n",
        "ax[1, 1].set_ylabel('')"
      ],
      "metadata": {
        "id": "SA1BKHXE_J2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Instantiate models\n",
        "knn = KNeighborsRegressor()\n",
        "svr = SVR()\n",
        "tree = DecisionTreeRegressor(max_depth = 10, random_state = 42)\n",
        "\n",
        "# Create a list which contains different scalers\n",
        "scalers = [norm, standard, robust]\n",
        "\n"
      ],
      "metadata": {
        "id": "VkKf1xMg_OZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
        "\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"Y_train shape: \", Y_train.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "print(\"Y_test shape: \", Y_test.shape)"
      ],
      "metadata": {
        "id": "GH0gXZKZ_QU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "knn_rmse = []\n",
        "\n",
        "# Without feature scaling\n",
        "knn.fit(X_train, Y_train)\n",
        "pred = knn.predict(X_test)\n",
        "knn_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
        "\n",
        "# Apply different scaling techniques and make predictions using KNN\n",
        "for scaler in scalers:\n",
        "    pipe = make_pipeline(scaler, knn)\n",
        "    pipe.fit(X_train, Y_train)\n",
        "    pred = pipe.predict(X_test)\n",
        "    knn_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
        "\n",
        "# Show results\n",
        "knn_df = pd.DataFrame({'RMSE': knn_rmse}, index = ['Original', 'MinMaxScaler', 'StandardScaler', 'RobustScaler'])\n",
        "knn_df\n",
        "\n"
      ],
      "metadata": {
        "id": "gXL6IjiL_S8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "svr_rmse = []\n",
        "\n",
        "# Without feature scaling\n",
        "svr.fit(X_train, Y_train)\n",
        "pred = svr.predict(X_test)\n",
        "svr_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
        "\n",
        "# Apply different scaling techniques and make predictions using SVR\n",
        "for scaler in scalers:\n",
        "    pipe = make_pipeline(scaler, svr)\n",
        "    pipe.fit(X_train, Y_train)\n",
        "    pred = pipe.predict(X_test)\n",
        "    svr_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
        "\n",
        "# Show results\n",
        "svr_df = pd.DataFrame({'RMSE': svr_rmse}, index = ['Original', 'MinMaxScaler', 'StandardScaler', 'RobustScaler'])\n",
        "svr_df\n",
        "\n"
      ],
      "metadata": {
        "id": "BUZ0JKij_Vxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_rmse = []\n",
        "\n",
        "# Without feature scaling\n",
        "tree.fit(X_train, Y_train)\n",
        "pred = tree.predict(X_test)\n",
        "tree_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
        "\n",
        "# Apply different scaling techniques and make predictions using decision tree\n",
        "for scaler in scalers:\n",
        "    pipe = make_pipeline(scaler, tree)\n",
        "    pipe.fit(X_train, Y_train)\n",
        "    pred = pipe.predict(X_test)\n",
        "    tree_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
        "\n",
        "# Show results\n",
        "tree_df = pd.DataFrame({'RMSE': tree_rmse}, index = ['Original', 'MinMaxScaler', 'StandardScaler', 'RobustScaler'])\n",
        "tree_df"
      ],
      "metadata": {
        "id": "CEdQlWSr_YJq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}