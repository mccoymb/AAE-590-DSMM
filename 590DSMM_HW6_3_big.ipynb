{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mccoymb/AAE-590-DSMM/blob/main/590DSMM_HW6_3_big.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "619a1a3c-50d9-40a9-a2d8-cf98e7be00aa",
      "metadata": {
        "id": "619a1a3c-50d9-40a9-a2d8-cf98e7be00aa"
      },
      "outputs": [],
      "source": [
        "# This was run in Jupyter Lab, will not work in colab\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "time_values = np.array([25000, 28000, 31000, 35000, 37500, 40000, 45000, 50000, 75000, 108000,\n",
        "                        180000, 220000, 250000, 270000, 300000, 360000, 430000, 540000, 900000, 1080000])\n",
        "log_time = np.log(time_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a1d2d658-86f6-4ea7-b6cd-57cfd15ea405",
      "metadata": {
        "id": "a1d2d658-86f6-4ea7-b6cd-57cfd15ea405",
        "outputId": "6407749a-b1a6-4f97-e2ef-80464da404cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/home/mccoymb/Downloads/train.npz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3d4a4de96b87>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/mccoymb/Downloads/train.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Keys in npz file:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_raw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_raw_data'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Shape: (200000, 1, 64, 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/mccoymb/Downloads/train.npz'"
          ]
        }
      ],
      "source": [
        "data = np.load('/home/mccoymb/Downloads/train.npz')\n",
        "\n",
        "print(\"Keys in npz file:\", data.files)\n",
        "input_raw_data = data['input_raw_data']  # Shape: (200000, 1, 64, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d318e7b2-3015-4d58-bc27-1289b650004e",
      "metadata": {
        "id": "d318e7b2-3015-4d58-bc27-1289b650004e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "a107f6fe-adfe-40ae-c77e-92e411cb3e11"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'input_raw_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c0c579006b7c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Loop through different sequence sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_sequences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msubset_raw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_raw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_sequences\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mall_grain_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_raw_data' is not defined"
          ]
        }
      ],
      "source": [
        "log_time = np.log(time_values)\n",
        "\n",
        "# Function to compute grain size\n",
        "def compute_grain_size(image):\n",
        "    _, binary = cv2.threshold((image * 255).astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    areas = [cv2.contourArea(cnt) for cnt in contours if cv2.contourArea(cnt) > 5]\n",
        "    return np.mean(areas) if areas else 1e-6\n",
        "\n",
        "# Final results list\n",
        "results = []\n",
        "\n",
        "# Loop through different sequence sizes\n",
        "for num_sequences in [10, 50, 100]:\n",
        "    subset_raw_data = input_raw_data[:num_sequences * 20]\n",
        "    all_grain_sizes = np.zeros((num_sequences, 20))\n",
        "\n",
        "    for seq in range(num_sequences):\n",
        "        imgs = subset_raw_data[seq * 20:(seq + 1) * 20, 0, :, :]\n",
        "        grain_sizes = np.array([compute_grain_size(img) for img in imgs])\n",
        "        first = max(grain_sizes[0], 1)\n",
        "        all_grain_sizes[seq] = grain_sizes / first\n",
        "\n",
        "    # Flatten and filter\n",
        "    X = np.tile(log_time, num_sequences)\n",
        "    y = all_grain_sizes.flatten()\n",
        "\n",
        "    # Outlier removal\n",
        "    Q1, Q3 = np.percentile(y, [25, 75])\n",
        "    IQR = Q3 - Q1\n",
        "    mask = (y >= Q1 - 1.5 * IQR) & (y <= Q3 + 1.5 * IQR)\n",
        "    X_filtered = X[mask].reshape(-1, 1)\n",
        "    y_filtered = y[mask]\n",
        "\n",
        "    # --- GPR ---\n",
        "    kernel = C(1.0, (1e-2, 1e2)) * RBF(1.0, (1e-2, 1e2))\n",
        "    gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.01, n_restarts_optimizer=10)\n",
        "    gpr.fit(X_filtered, y_filtered)\n",
        "    y_pred_gpr = gpr.predict(X_filtered)\n",
        "    r2 = r2_score(y_filtered, y_pred_gpr)\n",
        "    adj_r2 = 1 - (1 - r2) * (len(y_filtered) - 1) / (len(y_filtered) - 2)\n",
        "    mse = mean_squared_error(y_filtered, y_pred_gpr)\n",
        "    r, _ = pearsonr(y_filtered, y_pred_gpr)\n",
        "    cv_r2 = np.mean(cross_val_score(gpr, X_filtered, y_filtered, cv=5, scoring='r2'))\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": \"GPR\",\n",
        "        \"Sequences\": num_sequences,\n",
        "        \"R²\": round(r2, 4),\n",
        "        \"Adj. R²\": round(adj_r2, 4),\n",
        "        \"MSE\": round(mse, 6),\n",
        "        \"Pearson R\": round(r, 4),\n",
        "        \"CV R²\": round(cv_r2, 4)\n",
        "    })\n",
        "\n",
        "    # --- BLR ---\n",
        "    blr = BayesianRidge()\n",
        "    blr.fit(X_filtered, y_filtered)\n",
        "    y_pred_blr = blr.predict(X_filtered)\n",
        "    r2 = r2_score(y_filtered, y_pred_blr)\n",
        "    adj_r2 = 1 - (1 - r2) * (len(y_filtered) - 1) / (len(y_filtered) - 2)\n",
        "    mse = mean_squared_error(y_filtered, y_pred_blr)\n",
        "    r, _ = pearsonr(y_filtered, y_pred_blr)\n",
        "    cv_r2 = np.mean(cross_val_score(blr, X_filtered, y_filtered, cv=5, scoring='r2'))\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": \"Bayesian Ridge\",\n",
        "        \"Sequences\": num_sequences,\n",
        "        \"R²\": round(r2, 4),\n",
        "        \"Adj. R²\": round(adj_r2, 4),\n",
        "        \"MSE\": round(mse, 6),\n",
        "        \"Pearson R\": round(r, 4),\n",
        "        \"CV R²\": round(cv_r2, 4)\n",
        "    })\n",
        "\n",
        "# ----- Export Table -----\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.11 (Anaconda 2024.02)",
      "language": "python",
      "name": "anaconda-2024.02-py311"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}