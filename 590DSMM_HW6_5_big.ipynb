{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PbLVH0tHyx_UZcPDPzd_pISqeNeJ8KAB",
      "authorship_tag": "ABX9TyOmsO8FKUgRd1yuoUGocHY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mccoymb/AAE-590-DSMM/blob/main/590DSMM_HW6_5_big.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKTgVJuIO7HO",
        "outputId": "aef96f8c-c31e-40da-f970-2691bf94dbed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "onoCIXenOQ2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "time_values = np.array([25000, 28000, 31000, 35000, 37500, 40000, 45000, 50000, 75000, 108000,\n",
        "                        180000, 220000, 250000, 270000, 300000, 360000, 430000, 540000, 900000, 1080000])\n",
        "log_time = np.log(time_values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/drive/My Drive/590TrainingData/train.npz')\n",
        "print(\"Keys in npz file:\", data.files)\n",
        "input_raw_data = data['input_raw_data']  # Shape: (200000, 1, 64, 64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUwY1FhVOatd",
        "outputId": "437eebbf-da4c-4fa5-e538-c8ba22edc32f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in npz file: ['clips', 'dims', 'input_raw_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute grain size\n",
        "def compute_grain_size(image):\n",
        "    _, binary = cv2.threshold((image * 255).astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    areas = [cv2.contourArea(cnt) for cnt in contours if cv2.contourArea(cnt) > 5]  # Ignore small artifacts\n",
        "    return np.mean(areas) if areas else 1e-6  # Avoid division by zero\n",
        "\n",
        "# Final results\n",
        "results = []\n",
        "\n",
        "# Loop over different sequence counts\n",
        "for num_sequences in [50, 200, 500]:\n",
        "    subset_raw_data = input_raw_data[:num_sequences * 20]\n",
        "    all_grain_sizes = np.zeros((num_sequences, 20))\n",
        "\n",
        "    for seq in range(num_sequences):\n",
        "        images = subset_raw_data[seq * 20:(seq + 1) * 20, 0, :, :]\n",
        "        grain_sizes = np.array([compute_grain_size(img) for img in images])\n",
        "        first = max(grain_sizes[0], 1)\n",
        "        all_grain_sizes[seq] = grain_sizes / first\n",
        "\n",
        "    # Flatten and apply IQR filtering\n",
        "    X = np.tile(log_time, num_sequences)\n",
        "    y = all_grain_sizes.flatten()\n",
        "    Q1, Q3 = np.percentile(y, [25, 75])\n",
        "    IQR = Q3 - Q1\n",
        "    mask = (y >= Q1 - 1.5 * IQR) & (y <= Q3 + 1.5 * IQR)\n",
        "    X_filtered = X[mask]\n",
        "    y_filtered = y[mask]\n",
        "\n",
        "    # Normalize inputs\n",
        "    X_mean = X_filtered.mean()\n",
        "    X_std = X_filtered.std()\n",
        "    X_norm = (X_filtered - X_mean) / X_std\n",
        "    X_input = X_norm.reshape(-1, 1)\n",
        "    y_output = y_filtered.reshape(-1, 1)\n",
        "\n",
        "    # ANN model\n",
        "    model = Sequential([\n",
        "        Dense(32, activation='relu', input_shape=(1,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    model.fit(X_input, y_output, epochs=500, batch_size=32, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_input).flatten()\n",
        "\n",
        "    # Metrics\n",
        "    r, _ = pearsonr(y_filtered, y_pred)\n",
        "    r2 = r2_score(y_filtered, y_pred)\n",
        "    mse = mean_squared_error(y_filtered, y_pred)\n",
        "\n",
        "    results.append({\n",
        "        \"Sequences\": num_sequences,\n",
        "        \"R²\": round(r2, 4),\n",
        "        \"MSE\": round(mse, 6),\n",
        "        \"Pearson R\": round(r, 4)\n",
        "    })\n",
        "\n",
        "# Results table\n",
        "results_df = pd.DataFrame(results)\n",
        "csv_path = \"/content/ann_results_loop.csv\"\n",
        "results_df.to_csv(csv_path, index=False)\n",
        "print(results_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "ig9HJhU4OcZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f7313b-5d96-4874-d9d4-4e299de4141d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            " Sequences     R²      MSE  Pearson R\n",
            "        50 0.3825 0.042362     0.6398\n",
            "       200 0.2910 0.076758     0.5473\n",
            "       500 0.2877 0.091639     0.5377\n"
          ]
        }
      ]
    }
  ]
}